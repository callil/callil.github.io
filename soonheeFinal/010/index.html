<!--

This is the standard ThreeJS-based boilerplate for webVR
	currently being used by the eleVR team.

It has oculus support for webVR browsers, support for the non-VR web,
	and support for smartphone on google cardboard or similar VR device.

Supported Navigation Controls:
	WASD + E/Q navigation support for rotation.
	Arrow key navigation support for moving the location of the camera.
	Gamepad joystick navigation controls.
	Orientation control with a VR headset OR mobile phone.

Click to enter full-screen VR mode.

This boilerplate is based on Mozilla's boilerplate: https://github.com/MozVR/vr-web-examples/tree/master/threejs-vr-boilerplate

It has been developed with the help of a great many people including (but not limited to) Vi Hart, Andrew Lutomirski, Henry Segerman, and the Firefox webVR team.

-->

<!DOCTYPE html>

<html lang="en">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>three.js - kinect</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body {
				font-family: Monospace;
				background-color: #fff;
				margin: 0px;
				overflow: hidden;
			}

			#info {
				color: #ffffff;

				font-family: Monospace;
				font-size: 13px;
				text-align: center;
				font-weight: bold;

				position: absolute;
				top: 5px; width: 100%;
			}

			a {

				color: #0040ff;

			}
			#back{
				width: 40px;
				height: 60px;
				/*background-color: rgba(255,255,255,.6);*/
				border-radius: 10px;
				position: absolute;
				left: -5px;
				top: 400px;
			}

			#back a{
				color: white;
				font-size: 24px;
				padding: 10px;
				text-align: center;
			}

			#forward{
				width: 40px;
				height: 60px;
				/*background-color: rgba(255,255,255,.6);*/
				border-radius: 10px;
				position: absolute;
				right: -5px;
				top: 400px;
			}

			#forward a{
				color: white;
				font-size: 24px;
				padding: 10px;
				text-align: center;
			}
		</style>
	</head>

	<body>
	<div id="back">
			<a href="http://callil.github.io/soonheeFinal/09/index.html">⇽</a>
		</div>

		<div id="forward">
			<a href="http://callil.github.io/soonheeFinal/01/index.html">⇾</a>
	</div>

	<!--
	three.js 3d library
	-->
	<script src="js/three.min.js"></script>
	<script src='js/dat.gui.min.js'></script>

	<script src="js/Detector.js"></script>
	<script src="js/stats.min.js"></script>

	<!--
	PhoneVR acquires positional information from phone orientation. This is used by VRControls.js
	VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
	 -->
	<script src="js/PhoneVR.js"></script>
	<script src="js/VRControls.js"></script>

	<!--
	VREffect.js handles stereo camera setup and rendering.
	-->
	<script src="js/VREffect.js"></script>

	<script id="vs" type="x-shader/x-vertex">

			uniform sampler2D map;

			uniform float width;
			uniform float height;
			uniform float nearClipping, farClipping;

			uniform float pointSize;
			uniform float zOffset;

			varying vec2 vUv;

			const float XtoZ = 1.11146; // tan( 1.0144686 / 2.0 ) * 2.0;
			const float YtoZ = 0.83359; // tan( 0.7898090 / 2.0 ) * 2.0;

			void main() {

				vUv = vec2( position.x / width, position.y / height );

				vec4 color = texture2D( map, vUv );
				float depth = ( color.r + color.g + color.b ) / 3.0;

				// Projection code by @kcmic

				float z = ( 1.0 - depth ) * (farClipping - nearClipping) + nearClipping;

				vec4 pos = vec4(
					( position.x / width - 0.5 ) * z * XtoZ,
					( position.y / height - 0.5 ) * z * YtoZ,
					- z + zOffset,
					1.0);

				gl_PointSize = pointSize;
				gl_Position = projectionMatrix * modelViewMatrix * pos;

			}

		</script>

		<script id="fs" type="x-shader/x-fragment">

			uniform sampler2D map;

			varying vec2 vUv;

			void main() {

				vec4 color = texture2D( map, vUv );
				gl_FragColor = vec4( color.r, color.g, color.b, 0.2 );

			}

		</script>

		<script>
		var container;
		var geometry, cube, mesh, material;
		var mouse, center;
		var stats;

		var video, texture;


		// Setup three.js WebGL renderer
		var renderer = new THREE.WebGLRenderer();

		// Append the canvas element created by the renderer to document body element.
		document.body.appendChild( renderer.domElement );

		//Create a three.js scene
		var scene = new THREE.Scene();

		//Create a three.js camera
		var camera = new THREE.PerspectiveCamera( 110, window.innerWidth / window.innerHeight, 2, 10000 );
		camera.position.set( 0, 0, 500 );
		scene.add(camera);

		//Apply VR headset positional data to camera.
		var controls = new THREE.VRControls( camera );

		//Apply VR stereo rendering to renderer
		var effect = new THREE.VREffect( renderer );
		effect.setSize( window.innerWidth, window.innerHeight );

		container = document.createElement( 'div' );
		document.body.appendChild( container );

		center = new THREE.Vector3();
		center.z = - 1000;

		video = document.createElement( 'video' );
		video.addEventListener( 'loadedmetadata', function ( event ) {

			console.log("loaded");

			texture = new THREE.VideoTexture( video );
			texture.minFilter = THREE.NearestFilter;

			var width = 1280, height = 800;
			var nearClipping = 760, farClipping = 1;

			geometry = new THREE.BufferGeometry();

			var vertices = new Float32Array( width * height * 3 );

			for ( var i = 0, j = 0, l = vertices.length; i < l; i += 3, j ++ ) {

				vertices[ i ] = j % width;
				vertices[ i + 1 ] = Math.floor( j / width );

			}

			geometry.addAttribute( 'position', new THREE.BufferAttribute( vertices, 3 ) );

			material = new THREE.ShaderMaterial( {

				uniforms: {

					"map": { type: "t", value: texture },
					"width": { type: "f", value: width },
					"height": { type: "f", value: height },
					"nearClipping": { type: "f", value: nearClipping },
					"farClipping": { type: "f", value: farClipping },

					"pointSize": { type: "f", value: 2 },
					"zOffset": { type: "f", value: 0 }

				},
				vertexShader: document.getElementById( 'vs' ).textContent,
				fragmentShader: document.getElementById( 'fs' ).textContent,
				blending: THREE.AdditiveBlending,
				depthTest: false, depthWrite: false,
				transparent: true

			} );

			mesh = new THREE.Points( geometry, material );
			scene.add( mesh );

			// var gui = new dat.GUI();
			// gui.add( material.uniforms.nearClipping, 'value', 1, 10000, 1.0 ).name( 'nearClipping' );
			// gui.add( material.uniforms.farClipping, 'value', 1, 10000, 1.0 ).name( 'farClipping' );
			// gui.add( material.uniforms.pointSize, 'value', 1, 10, 1.0 ).name( 'pointSize' );
			// gui.add( material.uniforms.zOffset, 'value', 0, 4000, 1.0 ).name( 'zOffset' );
			// gui.close();


		}, false );
		video.loop = true;
		video.src = 'images/output3.webm';
		video.play();

		function animate() {

				controls.update();
				effect.render( scene, camera );
				requestAnimationFrame( animate );

			}

		if ( Detector.webgl ) {

			animate();

		} else {

			document.body.appendChild( Detector.getWebGLErrorMessage() );

		}

		// document.body.addEventListener( 'click', function(){
		//   effect.setFullScreen( true );
		// })

		/*
		Listen for keyboard events
		*/
		function onkey(event) {
		  event.preventDefault();

		  if (event.keyCode == 90) { // z
		    controls.resetSensor(); //zero rotation
		  } else if (event.keyCode == 70 || event.keyCode == 13) { //f or enter
		    effect.setFullScreen(true) //fullscreen
		  }
		};
		window.addEventListener("keydown", onkey, true);

		/*
		Handle window resizes
		*/
		function onWindowResize() {
		  camera.aspect = window.innerWidth / window.innerHeight;
		  camera.updateProjectionMatrix();
		  effect.setSize( window.innerWidth, window.innerHeight );
		}
		window.addEventListener( 'resize', onWindowResize, false );


		</script>

	</body>

</html>
